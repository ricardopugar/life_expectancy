{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dcc92e1-f967-4866-83d6-b08ceedc8eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2938, 22)\n",
      "       Country  Year      Status  Adult Mortality  infant deaths  Alcohol  \\\n",
      "0  Afghanistan  2015  Developing            263.0             62     0.01   \n",
      "1  Afghanistan  2014  Developing            271.0             64     0.01   \n",
      "2  Afghanistan  2013  Developing            268.0             66     0.01   \n",
      "3  Afghanistan  2012  Developing            272.0             69     0.01   \n",
      "4  Afghanistan  2011  Developing            275.0             71     0.01   \n",
      "\n",
      "   percentage expenditure  Hepatitis B  Measles    BMI   ...  \\\n",
      "0               71.279624         65.0      1154   19.1  ...   \n",
      "1               73.523582         62.0       492   18.6  ...   \n",
      "2               73.219243         64.0       430   18.1  ...   \n",
      "3               78.184215         67.0      2787   17.6  ...   \n",
      "4                7.097109         68.0      3013   17.2  ...   \n",
      "\n",
      "   Total expenditure  Diphtheria    HIV/AIDS         GDP  Population  \\\n",
      "0               8.16         65.0        0.1  584.259210  33736494.0   \n",
      "1               8.18         62.0        0.1  612.696514    327582.0   \n",
      "2               8.13         64.0        0.1  631.744976  31731688.0   \n",
      "3               8.52         67.0        0.1  669.959000   3696958.0   \n",
      "4               7.87         68.0        0.1   63.537231   2978599.0   \n",
      "\n",
      "    thinness  1-19 years   thinness 5-9 years  \\\n",
      "0                   17.2                 17.3   \n",
      "1                   17.5                 17.5   \n",
      "2                   17.7                 17.7   \n",
      "3                   17.9                 18.0   \n",
      "4                   18.2                 18.2   \n",
      "\n",
      "   Income composition of resources  Schooling  Life expectancy  \n",
      "0                            0.479       10.1             65.0  \n",
      "1                            0.476       10.0             59.9  \n",
      "2                            0.470        9.9             59.9  \n",
      "3                            0.463        9.8             59.5  \n",
      "4                            0.454        9.5             59.2  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "Index(['Country', 'Year', 'Status', 'Adult Mortality', 'infant deaths',\n",
      "       'Alcohol', 'percentage expenditure', 'Hepatitis B', 'Measles ', ' BMI ',\n",
      "       'under-five deaths ', 'Polio', 'Total expenditure', 'Diphtheria ',\n",
      "       ' HIV/AIDS', 'GDP', 'Population', ' thinness  1-19 years',\n",
      "       ' thinness 5-9 years', 'Income composition of resources', 'Schooling',\n",
      "       'Life expectancy'],\n",
      "      dtype='object')\n",
      "count    2938.000000\n",
      "mean       69.234717\n",
      "std         9.509115\n",
      "min        36.300000\n",
      "25%        63.200000\n",
      "50%        72.100000\n",
      "75%        75.600000\n",
      "max        89.000000\n",
      "Name: Life expectancy, dtype: float64\n",
      "      Year  Adult Mortality  infant deaths  Alcohol  percentage expenditure  \\\n",
      "0     2015            263.0             62     0.01               71.279624   \n",
      "1     2014            271.0             64     0.01               73.523582   \n",
      "2     2013            268.0             66     0.01               73.219243   \n",
      "3     2012            272.0             69     0.01               78.184215   \n",
      "4     2011            275.0             71     0.01                7.097109   \n",
      "...    ...              ...            ...      ...                     ...   \n",
      "2933  2004            723.0             27     4.36                0.000000   \n",
      "2934  2003            715.0             26     4.06                0.000000   \n",
      "2935  2002             73.0             25     4.43                0.000000   \n",
      "2936  2001            686.0             25     1.72                0.000000   \n",
      "2937  2000            665.0             24     1.68                0.000000   \n",
      "\n",
      "      Hepatitis B  Measles    BMI   under-five deaths   Polio  ...  \\\n",
      "0            65.0      1154   19.1                  83    6.0  ...   \n",
      "1            62.0       492   18.6                  86   58.0  ...   \n",
      "2            64.0       430   18.1                  89   62.0  ...   \n",
      "3            67.0      2787   17.6                  93   67.0  ...   \n",
      "4            68.0      3013   17.2                  97   68.0  ...   \n",
      "...           ...       ...    ...                 ...    ...  ...   \n",
      "2933         68.0        31   27.1                  42   67.0  ...   \n",
      "2934          7.0       998   26.7                  41    7.0  ...   \n",
      "2935         73.0       304   26.3                  40   73.0  ...   \n",
      "2936         76.0       529   25.9                  39   76.0  ...   \n",
      "2937         79.0      1483   25.5                  39   78.0  ...   \n",
      "\n",
      "      Diphtheria    HIV/AIDS         GDP  Population   thinness  1-19 years  \\\n",
      "0            65.0        0.1  584.259210  33736494.0                   17.2   \n",
      "1            62.0        0.1  612.696514    327582.0                   17.5   \n",
      "2            64.0        0.1  631.744976  31731688.0                   17.7   \n",
      "3            67.0        0.1  669.959000   3696958.0                   17.9   \n",
      "4            68.0        0.1   63.537231   2978599.0                   18.2   \n",
      "...           ...        ...         ...         ...                    ...   \n",
      "2933         65.0       33.6  454.366654  12777511.0                    9.4   \n",
      "2934         68.0       36.7  453.351155  12633897.0                    9.8   \n",
      "2935         71.0       39.8   57.348340    125525.0                    1.2   \n",
      "2936         75.0       42.1  548.587312  12366165.0                    1.6   \n",
      "2937         78.0       43.5  547.358879  12222251.0                   11.0   \n",
      "\n",
      "       thinness 5-9 years  Income composition of resources  Schooling  \\\n",
      "0                    17.3                            0.479       10.1   \n",
      "1                    17.5                            0.476       10.0   \n",
      "2                    17.7                            0.470        9.9   \n",
      "3                    18.0                            0.463        9.8   \n",
      "4                    18.2                            0.454        9.5   \n",
      "...                   ...                              ...        ...   \n",
      "2933                  9.4                            0.407        9.2   \n",
      "2934                  9.9                            0.418        9.5   \n",
      "2935                  1.3                            0.427       10.0   \n",
      "2936                  1.7                            0.427        9.8   \n",
      "2937                 11.2                            0.434        9.8   \n",
      "\n",
      "      Status_Developed  Status_Developing  \n",
      "0                False               True  \n",
      "1                False               True  \n",
      "2                False               True  \n",
      "3                False               True  \n",
      "4                False               True  \n",
      "...                ...                ...  \n",
      "2933             False               True  \n",
      "2934             False               True  \n",
      "2935             False               True  \n",
      "2936             False               True  \n",
      "2937             False               True  \n",
      "\n",
      "[2938 rows x 21 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">737</span> (2.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m737\u001b[0m (2.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">737</span> (2.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m737\u001b[0m (2.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 550732818284544.0000 - mae: 2942283.7500 - val_loss: 1863830912.0000 - val_mae: 14294.5557\n",
      "Epoch 2/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 251944484864.0000 - mae: 113088.2969 - val_loss: 92467003392.0000 - val_mae: 92697.4375\n",
      "Epoch 3/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2324108673024.0000 - mae: 182614.2969 - val_loss: 793018499072.0000 - val_mae: 270503.8438\n",
      "Epoch 4/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8579608215552.0000 - mae: 543125.0625 - val_loss: 5524427898880.0000 - val_mae: 701256.2500\n",
      "Epoch 5/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 66893264191488.0000 - mae: 1166343.6250 - val_loss: 695463313408.0000 - val_mae: 266467.9375\n",
      "Epoch 6/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13912901681152.0000 - mae: 510405.5000 - val_loss: 33729134592.0000 - val_mae: 57060.4531\n",
      "Epoch 7/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1158655901696.0000 - mae: 172029.2812 - val_loss: 322942664704.0000 - val_mae: 168017.4375\n",
      "Epoch 8/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1467590770688.0000 - mae: 200288.6562 - val_loss: 102869123072.0000 - val_mae: 95152.6094\n",
      "Epoch 9/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 640859832320.0000 - mae: 135128.0781 - val_loss: 64132444160.0000 - val_mae: 86456.6328\n",
      "Epoch 10/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 90988519424.0000 - mae: 97587.0547 - val_loss: 1055326080.0000 - val_mae: 16866.7246\n",
      "Epoch 11/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 338574999552.0000 - mae: 83436.2188 - val_loss: 238234058752.0000 - val_mae: 143857.4062\n",
      "Epoch 12/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 346066550784.0000 - mae: 153182.0000 - val_loss: 28526155776.0000 - val_mae: 50110.8594\n",
      "Epoch 13/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 333384810496.0000 - mae: 128762.0156 - val_loss: 57986478080.0000 - val_mae: 70364.0938\n",
      "Epoch 14/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1337266929664.0000 - mae: 225747.5469 - val_loss: 86055469056.0000 - val_mae: 86038.0000\n",
      "Epoch 15/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 38010134528.0000 - mae: 48672.7461 - val_loss: 584316608.0000 - val_mae: 14651.7783\n",
      "Epoch 16/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4549348352.0000 - mae: 18493.0469 - val_loss: 175445392.0000 - val_mae: 9092.8359\n",
      "Epoch 17/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2929627904.0000 - mae: 12435.8750 - val_loss: 146016816.0000 - val_mae: 8517.2979\n",
      "Epoch 18/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2563077632.0000 - mae: 12073.7480 - val_loss: 232728480.0000 - val_mae: 7629.9521\n",
      "Epoch 19/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9020167168.0000 - mae: 20917.3984 - val_loss: 5169969664.0000 - val_mae: 20885.6016\n",
      "Epoch 20/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76223176704.0000 - mae: 40652.0039 - val_loss: 916300480.0000 - val_mae: 13706.7842\n",
      "Epoch 21/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 315808896.0000 - mae: 9417.2607 - val_loss: 48213360.0000 - val_mae: 5438.6279\n",
      "Epoch 22/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 83930120.0000 - mae: 5346.4800 - val_loss: 59651772.0000 - val_mae: 4701.6206\n",
      "Epoch 23/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 102609896.0000 - mae: 4953.8076 - val_loss: 208971360.0000 - val_mae: 8001.3608\n",
      "Epoch 24/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 933943296.0000 - mae: 9196.0508 - val_loss: 32043470.0000 - val_mae: 4014.2778\n",
      "Epoch 25/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 805449856.0000 - mae: 6768.9570 - val_loss: 384213856.0000 - val_mae: 9370.5938\n",
      "Epoch 26/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 151518688.0000 - mae: 6406.9341 - val_loss: 266359344.0000 - val_mae: 8119.2842\n",
      "Epoch 27/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6202761216.0000 - mae: 14221.1748 - val_loss: 10119733248.0000 - val_mae: 28794.1602\n",
      "Epoch 28/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 409459884032.0000 - mae: 103481.4609 - val_loss: 1591159422976.0000 - val_mae: 381864.9375\n",
      "Epoch 29/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17275133362176.0000 - mae: 697456.0625 - val_loss: 43855646720.0000 - val_mae: 74631.3672\n",
      "Epoch 30/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 453215453184.0000 - mae: 118159.5156 - val_loss: 1387519410176.0000 - val_mae: 350706.3438\n",
      "Epoch 31/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1431173464064.0000 - mae: 343888.8438 - val_loss: 150203301888.0000 - val_mae: 130306.3516\n",
      "Epoch 32/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3993050021888.0000 - mae: 279954.2188 - val_loss: 267568594944.0000 - val_mae: 153692.4531\n",
      "Epoch 33/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 513079017472.0000 - mae: 119606.3047 - val_loss: 128361938944.0000 - val_mae: 107448.6953\n",
      "Epoch 34/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2722932719616.0000 - mae: 294135.0938 - val_loss: 868386471936.0000 - val_mae: 298451.0938\n",
      "Epoch 35/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58861885063168.0000 - mae: 1147419.2500 - val_loss: 4100051173376.0000 - val_mae: 629208.3750\n",
      "Epoch 36/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23413374582784.0000 - mae: 701128.2500 - val_loss: 1535751424.0000 - val_mae: 20763.1211\n",
      "Epoch 37/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23073869824.0000 - mae: 34950.5703 - val_loss: 496890560.0000 - val_mae: 11940.7549\n",
      "Epoch 38/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1224309504.0000 - mae: 13572.6377 - val_loss: 482322848.0000 - val_mae: 13236.9287\n",
      "Epoch 39/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 462167008.0000 - mae: 12359.2178 - val_loss: 364060128.0000 - val_mae: 10947.4844\n",
      "Epoch 40/40\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 392036512.0000 - mae: 10830.1064 - val_loss: 348618112.0000 - val_mae: 10887.1240\n",
      "4828.5341796875\n",
      "68.76666259765625\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "#Loading data...\n",
    "dataset = pd.read_csv('life_expectancy.csv', encoding='latin1')\n",
    "\n",
    "#EDA\n",
    "print(dataset.shape)\n",
    "print(dataset.head(5))\n",
    "print(dataset.columns)\n",
    "print(dataset['Life expectancy'].describe())\n",
    "\n",
    "#Manipulating data\n",
    "dataset = dataset.drop(['Country'], axis=1)\n",
    "\n",
    "labels = dataset.iloc[: , -1]\n",
    "features = dataset.iloc[:, 0:-1]\n",
    "\n",
    "#encoding\n",
    "features = pd.get_dummies(features)\n",
    "print(features)\n",
    "\n",
    "#Spliting and transforming data \n",
    "features_train,  features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.3, random_state=23)\n",
    "\n",
    "numerical_features = features.select_dtypes(include=['float64', 'int64'])\n",
    "numerical_columns = numerical_features.columns\n",
    "ct = ColumnTransformer([('only numeric', StandardScaler(), numerical_columns)], remainder='passthrough')\n",
    "\n",
    "features_train_scaled = ct.fit_transform(features_train)\n",
    "features_test_scaled = ct.transform(features_test)\n",
    "\n",
    "#model instance and layer addition\n",
    "my_model = Sequential()\n",
    "input = InputLayer(shape = (features.shape[1], ))\n",
    "my_model.add(input)\n",
    "my_model.add(Dense(32, activation='relu'))\n",
    "my_model.add(Dense(1))\n",
    "print(my_model.summary())\n",
    "\n",
    "#initializing optimizer and compiling model\n",
    "opt = Adam(learning_rate = 0.01)\n",
    "my_model.compile(loss= 'mse', metrics= ['mae'], optimizer= opt)\n",
    "\n",
    "#model fitting and evaluation\n",
    "my_model.fit(features_train, labels_train, validation_split=0.2, epochs=40, batch_size=32, verbose=1)\n",
    "res_mse, res_mae = my_model.evaluate(features_test_scaled, labels_test, verbose=0)\n",
    "\n",
    "print(res_mse)\n",
    "print(res_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900fc1ad-ef72-4171-941f-e109ce334530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
